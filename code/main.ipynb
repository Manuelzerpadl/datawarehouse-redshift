{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import getpass\n",
    "import configparser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter AWS KEY and Secret\n",
    "KEY = getpass.getpass(prompt='Enter AWS Access key ID:')\n",
    "SECRET = getpass.getpass(prompt='Enter AWS Secret access key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DWH Params from config file\n",
    "CONFIG_FILE = 'dwh.cfg'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(CONFIG_FILE)\n",
    "\n",
    "REGION                 = config.get(\"AWS\",\"REGION\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"IAM\",\"ROLE_NAME\")\n",
    "\n",
    "DWH_ENDPOINT           = config.get(\"CLUSTER\",\"HOST\")\n",
    "DWH_DB                 = config.get(\"CLUSTER\",\"DB_NAME\")\n",
    "DWH_DB_USER            = config.get(\"CLUSTER\",\"DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"CLUSTER\",\"DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"CLUSTER\",\"DB_PORT\")\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients to access AWS resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created clients for S3, AM and Redshift\n",
    "s3 = boto3.resource('s3',\n",
    "                    region_name=REGION,\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET\n",
    "                   )\n",
    "\n",
    "iam = boto3.client('iam',\n",
    "                   region_name=REGION,\n",
    "                   aws_access_key_id=KEY,\n",
    "                   aws_secret_access_key=SECRET\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                        region_name=REGION,\n",
    "                        aws_access_key_id=KEY,\n",
    "                        aws_secret_access_key=SECRET\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the sample data sources on S3 \n",
    "sampleDbBucket =  s3.Bucket(\"udacity-dend\")\n",
    "\n",
    "for obj in sampleDbBucket.objects.filter(Prefix=\"log_data\"):\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAM ROLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)\n",
    "try:\n",
    "    print('Creating a new IAM Role')\n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {\n",
    "                'Statement': [\n",
    "                    {\n",
    "                        'Action': 'sts:AssumeRole',\n",
    "                        'Effect': 'Allow',\n",
    "                        'Principal': {'Service': 'redshift.amazonaws.com'}\n",
    "                    }\n",
    "                ],\n",
    "                'Version': '2012-10-17'}\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Attaching Policy')\n",
    "iam.attach_role_policy(\n",
    "    RoleName=DWH_IAM_ROLE_NAME,\n",
    "    PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    ")['ResponseMetadata']['HTTPStatusCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Get the IAM role ARN')\n",
    "DWH_ROLE_ARN = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(DWH_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update config file with DWH_ROLE_ARN\n",
    "config.set(\"IAM\",\"ROLE_ARN\", DWH_ROLE_ARN)\n",
    "with open(CONFIG_FILE, \"w+\") as configfile:\n",
    "    config.write(configfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REDSHIFT CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RedShift Cluster\n",
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        # Add parameters for hardware\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "\n",
    "        # Add parameters for identifiers & credentials\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        \n",
    "        # Add parameter for role (to allow s3 access)\n",
    "        IamRoles=[DWH_ROLE_ARN]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for cluster getting created\n",
    "print('Redshift Cluster is getting created...')\n",
    "cluster_status = 'creating'\n",
    "while cluster_status != \"available\":\n",
    "    myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "    cluster_status = myClusterProps['ClusterStatus']\n",
    "    time.sleep(5)\n",
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "print(f'Cluster status: {cluster_status} \\nEndpoint: {DWH_ENDPOINT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update config file with DWH_ENDPOINT\n",
    "config.set(\"CLUSTER\",\"HOST\", DWH_ENDPOINT)\n",
    "with open(CONFIG_FILE, \"w+\") as configfile:\n",
    "    config.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish conection to the cluster\n",
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create staging, fact and dim tables\n",
    "!python3 create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL\n",
    "!python3 etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check count of staging, fact and dim tables entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT count(*) FROM staging_events;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT count(*) FROM staging_songs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT count(*) FROM songplays;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up resoruces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cluster\n",
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for cluster deletion\n",
    "print('Redshift Cluster is getting getting deleted...')\n",
    "cluster_status = 'deleting'\n",
    "while cluster_status == \"deleting\":\n",
    "    try:\n",
    "        myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "        cluster_status = myClusterProps['ClusterStatus']\n",
    "        time.sleep(5)\n",
    "    except Exception as e:\n",
    "        break\n",
    "print(f'{DWH_CLUSTER_IDENTIFIER} has been deleted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete IAM Role\n",
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analisis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
